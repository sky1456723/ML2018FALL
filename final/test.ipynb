{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEVICE ###\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(\"../\",\"data\",\"ntu_final_data\")\n",
    "\n",
    "test_file = pd.read_csv(os.path.join(root_dir,\"medical_images\",\"test.csv\"))\n",
    "test_data = []\n",
    "for i in test_file.index:\n",
    "    test_data.append(test_file.loc[i][\"Image Index\"])\n",
    "img_dirs = os.path.join(root_dir,\"medical_images\",\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(data_list):\n",
    "    part_data = []\n",
    "    print(len(data_list))\n",
    "    for i, name in enumerate(data_list):\n",
    "        print(i,end='\\r')\n",
    "        img = Image.open(os.path.join(img_dirs, name))\n",
    "        img = img.convert(mode=\"L\")\n",
    "        img = img.resize((512,512))\n",
    "        img = np.array(img)\n",
    "        img = np.expand_dims(img, axis=0) / 255\n",
    "        part_data.append(img)\n",
    "\n",
    "    batch = 10\n",
    "    label_data_x = torch.Tensor(part_data)\n",
    "    label_dataset = torch.utils.data.TensorDataset(label_data_x)\n",
    "    label_dataloader = torch.utils.data.DataLoader(dataset = label_dataset,\n",
    "                                                   batch_size =batch,\n",
    "                                                   shuffle = False,\n",
    "                                                   num_workers = 1 )\n",
    "    del part_data\n",
    "    return label_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part  0\n",
      "1000\n",
      "Part  1 99\n",
      "1000\n",
      "Part  2 99\n",
      "1000\n",
      "Part  3 99\n",
      "1000\n",
      "Part  4 99\n",
      "1000\n",
      "Part  5 99\n",
      "1000\n",
      "Part  6 99\n",
      "1000\n",
      "Part  7 99\n",
      "1000\n",
      "Part  8 99\n",
      "1000\n",
      "Part  9 99\n",
      "1000\n",
      "Part  1099\n",
      "1000\n",
      "Part  1199\n",
      "1000\n",
      "Part  1299\n",
      "1000\n",
      "Part  1399\n",
      "1000\n",
      "Part  1499\n",
      "1000\n",
      "Part  1599\n",
      "1000\n",
      "Part  1699\n",
      "1000\n",
      "Part  1799\n",
      "1000\n",
      "Part  1899\n",
      "1000\n",
      "Part  1999\n",
      "1000\n",
      "Part  2099\n",
      "1000\n",
      "Part  2199\n",
      "1000\n",
      "Part  2299\n",
      "1000\n",
      "Part  2399\n",
      "1000\n",
      "Part  2499\n",
      "1000\n",
      "Part  2599\n",
      "1000\n",
      "Part  2699\n",
      "1000\n",
      "Part  2799\n",
      "1000\n",
      "Part  2899\n",
      "1000\n",
      "Part  2999\n",
      "1000\n",
      "Part  3099\n",
      "1000\n",
      "Part  3199\n",
      "1000\n",
      "Part  3299\n",
      "1000\n",
      "Part  3399\n",
      "652\n",
      "Batch:  65\r"
     ]
    }
   ],
   "source": [
    "model_name = \"test2_epoch10.pkl\"\n",
    "model_path = os.path.join(\"./\",model_name)\n",
    "model = torch.load(model_path).to(device)\n",
    "model = model.eval()\n",
    "\n",
    "count = 0\n",
    "last = False\n",
    "ans_list = []\n",
    "class_name = open(os.path.join(root_dir,\"medical_images\",\"classname.txt\")).readlines()\n",
    "first_row=[\"id\"]\n",
    "first_row.extend([name.replace(\"\\n\",\"\") for name in class_name])\n",
    "#ans_list.append(first_row)\n",
    "while not last:\n",
    "    if len(test_data[count*1000:(count+1)*1000]) == 0:\n",
    "        break\n",
    "    print(\"Part \",count)\n",
    "    dataloader = get_dataloader(test_data[count*1000:(count+1)*1000])\n",
    "    count += 1\n",
    "    for i, data in enumerate(dataloader):\n",
    "        print(\"Batch: \", i, end='\\r')\n",
    "        pred = model.output_act( model(model.pre_conv(data[0].to(device))) )\n",
    "        for one_row in pred.cpu().data.numpy():\n",
    "            ans_list.append(one_row)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output_id = np.expand_dims(np.array(test_data),axis=1)\n",
    "output = np.hstack((output_id, ans_list))\n",
    "output = np.vstack((first_row, output))\n",
    "output = pd.DataFrame(output)\n",
    "output.to_csv(\"result.csv\",index=None,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33652"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "999\r"
     ]
    }
   ],
   "source": [
    "dataloader = get_dataloader(test_data[count*1000:(count+1)*1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=torch.Tensor([a,a,a])\n",
    "d=torch.utils.data.TensorDataset(c,c)\n",
    "e=torch.utils.data.DataLoader(dataset = d, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[1.1000],\n",
      "         [3.3000],\n",
      "         [5.5000],\n",
      "         [7.7000]],\n",
      "\n",
      "        [[1.1000],\n",
      "         [3.3000],\n",
      "         [5.5000],\n",
      "         [7.7000]]]), tensor([[[1.1000],\n",
      "         [3.3000],\n",
      "         [5.5000],\n",
      "         [7.7000]],\n",
      "\n",
      "        [[1.1000],\n",
      "         [3.3000],\n",
      "         [5.5000],\n",
      "         [7.7000]]])]\n",
      "[tensor([[[1.1000],\n",
      "         [3.3000],\n",
      "         [5.5000],\n",
      "         [7.7000]]]), tensor([[[1.1000],\n",
      "         [3.3000],\n",
      "         [5.5000],\n",
      "         [7.7000]]])]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
